# ğŸ›’ CHURNBR â€“ Pipeline de Machine Learning para Churn em E-commerce

Este projeto Ã© o MVP de CiÃªncia de Dados desenvolvido por mim como parte do curso da PUC-Rio. O objetivo foi construir um pipeline completo, reprodutÃ­vel e orientado a negÃ³cio para **prever churn de clientes** em e-commerce, utilizando **Google Colab**, **scikit-learn** e boas prÃ¡ticas de ML (pipelines, validaÃ§Ã£o, tuning e seleÃ§Ã£o de limiar).

> **Notebook (abrir no Colab):**  
> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wallace91x/ecommerce-churn-mvp-machine-learning/blob/main/notebooks/mvp_churn_ecommerce.ipynb)

---

## ğŸ§  Objetivo do Projeto

Identificar clientes com alta probabilidade de **churn** e apoiar aÃ§Ãµes de retenÃ§Ã£o. O projeto responde a perguntas-chave:

- Quais modelos e prÃ©-processamentos alcanÃ§am melhor desempenho?  
- Qual **limiar de decisÃ£o** maximiza **recall** sem perder precisÃ£o de forma crÃ­tica?  
- Qual o **impacto financeiro** (ROI) ao acionar clientes com base nas previsÃµes (parÃ¢metros de negÃ³cio **C**, **V**, **R**)?

---

## ğŸš€ Stack Utilizada

- **Python (Google Colab)**
- **pandas, numpy, matplotlib, seaborn**
- **scikit-learn** (Pipeline, ColumnTransformer, GridSearchCV, mÃ©tricas, curvas ROC/PR)
- **kagglehub** (ingestÃ£o automÃ¡tica do dataset)
- **joblib** (persistÃªncia opcional de artefatos)

---

## ğŸ“‚ Estrutura do Projeto

| Pasta / Arquivo                                 | DescriÃ§Ã£o                                                                 |
|--------------------------------------------------|---------------------------------------------------------------------------|
| `notebooks/mvp_churn_ecommerce.ipynb`            | Notebook principal com ingestÃ£o, EDA leve, modelagem e avaliaÃ§Ã£o         |
| `requirements.txt`                               | DependÃªncias para reproduÃ§Ã£o                                             |
| `.gitignore`                                     | Regras para nÃ£o versionar dados/modelos grandes                           |
| `README.md`                                      | Este arquivo com visÃ£o geral do projeto                                   |

> O dataset Ã© baixado em runtime via **kagglehub**; a pasta `data/` nÃ£o Ã© versionada.

---

## ğŸ”„ Etapas do Projeto

### 1. ğŸ“¥ IngestÃ£o e OrganizaÃ§Ã£o
- Fonte: **Ecommerce Customer Churn Analysis and Prediction** (Kaggle), via `kagglehub`.  
- Checagens iniciais, mapeamento de tipos e **split estratificado 60/20/20** (treino/validaÃ§Ã£o/teste) evitando vazamento.

### 2. ğŸ§¼ PreparaÃ§Ã£o e PrÃ©-processamento
- ImputaÃ§Ã£o de ausentes, tratamento de outliers, seleÃ§Ã£o de atributos Ãºteis.  
- **`ColumnTransformer`**: numÃ©ricos (imputaÃ§Ã£o + *scaler*) e categÃ³ricos (One-Hot).  
- Tudo dentro de **Pipeline** para garantir reprodutibilidade.

### 3. ğŸ—ï¸ Modelagem e Tuning
- **Baseline** com Dummy para referÃªncia.  
- Modelos comparados: **KNN**, **DecisionTree**, **NaiveBayes**, **SVM (RBF)**.  
- **GridSearchCV** (ROC AUC como *scoring*), *seeds* fixas e tabela de **tempos de treino**.

### 4. ğŸ¯ Limiar de DecisÃ£o & NegÃ³cio
- ComparaÃ§Ã£o de limiares: **padrÃ£o (0.50)**, **F2 (~0.29)** e **meta (~0.223)**.  
- FunÃ§Ã£o de **ROI paramÃ©trico** com entrada do usuÃ¡rio:  
  - **C** = custo de contato por cliente,  
  - **V** = valor monetÃ¡rio mÃ©dio do cliente,  
  - **R** = taxa de recuperaÃ§Ã£o (sucesso da aÃ§Ã£o).  
- CÃ¡lculo de **Lucro, Receita salva, Custos** e **Custo ImplÃ­cito do FN** para suportar decisÃ£o.

### 5. ğŸ“Š AvaliaÃ§Ã£o e ValidaÃ§Ã£o
- MÃ©tricas: **AcurÃ¡cia, PrecisÃ£o, Recall/Sensibilidade, Especificidade, ROC AUC**.  
- **Curvas ROC e Precisionâ€“Recall** (validaÃ§Ã£o e teste) e **matriz de confusÃ£o**.  
- SeleÃ§Ã£o do modelo/limiar com melhor equilÃ­brio para o objetivo de **retenÃ§Ã£o**.

---

## ğŸ“ˆ Resultados Visuais

- Curvas **ROC** e **Precisionâ€“Recall** (comparaÃ§Ã£o entre modelos e no teste)  
- **Matriz de confusÃ£o** no teste  
- Tabela comparativa de mÃ©tricas e **tempos de treino** por modelo

---

## ğŸ’¬ ConclusÃµes

- O melhor desempenho global foi do **SVM (RBF)**; com limiar **F2 â‰ˆ 0,29** priorizamos **Recall** (retenÃ§Ã£o) mantendo boa **PrecisÃ£o**.  
- No **teste**, desempenho tÃ­pico observado: **AUC â‰ˆ 0,981**, **Acc â‰ˆ 0,950**, **Prec â‰ˆ 0,805**, **Recall â‰ˆ 0,932**, **Spec â‰ˆ 0,954** (churn â‰ˆ 16,8%).  
- A anÃ¡lise de **ROI** com parÃ¢metros de negÃ³cio (ex.: **C=R$3,50**, **V=R$260**, **R=25%**) indicou **lucro positivo** ao acionar clientes de alto risco.  
- Pipeline Ã© reprodutÃ­vel (seeds fixas, *pipelines*, *split* estratificado) e facilmente extensÃ­vel (ex.: calibrar probabilidades, testar XGBoost/LightGBM, *cost-sensitive learning*).

---

## ğŸ“„ LicenÃ§a

Este projeto possui fins acadÃªmicos. O uso dos dados e do cÃ³digo Ã© permitido mediante atribuiÃ§Ã£o ao autor.

---

## ğŸ‘¨â€ğŸ’» Autor

**Wallace Lima**  
CiÃªncia e AnÃ¡lise de Dados | Engenharia de Dados | FinanÃ§as | Compliance  
[LinkedIn](https://www.linkedin.com/in/wallacelima17/)
